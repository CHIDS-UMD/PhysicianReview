{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba6fd86",
   "metadata": {},
   "source": [
    "# Get NPPES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e5665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:18:02.569577Z",
     "start_time": "2021-11-08T01:18:01.192315Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "NPPES = pd.read_pickle('Data/NPPES/NPI2InfoMDDO.p')\n",
    "NPPESNames = NPPES[['NPI', 'LastName', 'FirstName', 'Gender']]\n",
    "nppes_set = set(NPPESNames['NPI'].unique())\n",
    "print(NPPESNames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe67ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:18:02.607388Z",
     "start_time": "2021-11-08T01:18:02.570817Z"
    }
   },
   "outputs": [],
   "source": [
    "suffix = '_stand'\n",
    "website2path = {\n",
    "    'healthgrades': 'healthgrades_reviews{}.p'.format(suffix), \n",
    "    'vitals': 'vitals_reviews{}.p'.format(suffix), \n",
    "    'ratemds': 'ratemds_reviews{}.p'.format(suffix), \n",
    "    'yelp': 'yelp_reviews_detailed{}.p'.format(suffix),\n",
    "    'zocdoc': 'zocdoc_reviews{}.p'.format(suffix)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee1248",
   "metadata": {},
   "source": [
    "# Get IgnoreNPI List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef5a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:18:12.400248Z",
     "start_time": "2021-11-08T01:18:02.608323Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_website2ignorenpis(website2path, nppes_set):\n",
    "    website2ignorenpis = {}\n",
    "\n",
    "    # healthgrades\n",
    "    website2ignorenpis['healthgrades'] = []\n",
    "\n",
    "    # vitals\n",
    "    website2ignorenpis['vitals'] = []\n",
    "\n",
    "    # ratemds\n",
    "    path = 'Data/ToIgnore/ToIgnoreRateMDs.csv'\n",
    "    ratemds_ignore_npis = pd.read_csv(path)['NPI'].to_list()\n",
    "    website2ignorenpis['ratemds'] = ratemds_ignore_npis\n",
    "\n",
    "    # zocdoc\n",
    "    website2ignorenpis['zocdoc'] = []\n",
    "\n",
    "    # yelp\n",
    "    path = 'Data/ToIgnore/ToIgnoreYelp.csv'\n",
    "    yelp_ignore_npis = pd.read_csv(path)['NPI'].to_list()\n",
    "    # print(len(yelp_ignore_npis))\n",
    "    website2ignorenpis['yelp'] = yelp_ignore_npis\n",
    "\n",
    "    # match with NPPES\n",
    "    for name, path in website2path.items():\n",
    "        path = os.path.join('Data/Reviews', path)\n",
    "        df = pd.read_pickle(path)\n",
    "        web_npi_set = set(df['NPI'])\n",
    "        to_ignore_new = list(web_npi_set - nppes_set)\n",
    "        website2ignorenpis[name] = website2ignorenpis[name] + to_ignore_new\n",
    "        \n",
    "    return website2ignorenpis\n",
    "\n",
    "\n",
    "website2ignorenpis = get_website2ignorenpis(website2path, nppes_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718cd431",
   "metadata": {},
   "source": [
    "# Filter Physcians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4a14f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:18:24.223274Z",
     "start_time": "2021-11-08T01:18:12.401893Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_website2validphyDF(website2path, website2ignorenpis):\n",
    "    Report = []\n",
    "    website2df = {}\n",
    "    for name, path in website2path.items():\n",
    "        path = os.path.join('Data/Reviews', path)\n",
    "        d = {}\n",
    "        d['name'] = name\n",
    "\n",
    "        # input data\n",
    "        df = pd.read_pickle(path)\n",
    "        website2df[name] = df\n",
    "        d['RawNum'] = len(df)\n",
    "\n",
    "        # drop duplicates\n",
    "        a = df['NPI'].drop_duplicates()\n",
    "        df = df.loc[a.index].reset_index(drop = True)\n",
    "        d['UnqNum'] = len(df)\n",
    "\n",
    "        # match or not\n",
    "        ignore_npis = website2ignorenpis[name]\n",
    "        d['ToIgnore'] = len(ignore_npis)\n",
    "        df = df[-df['NPI'].isin(ignore_npis)].reset_index(drop = True)\n",
    "        d['MchNum'] = len(df)\n",
    "\n",
    "        # valid profile score or not\n",
    "        df['reported_profile_score'] = df['reported_profile_score'].astype(float)\n",
    "        df = df[- (df['reported_profile_score'] > 5)].reset_index(drop = True)\n",
    "        df = df[- (df['reported_profile_score'] < 0)].reset_index(drop = True)\n",
    "        website2df[name] = df\n",
    "        d['FnlNum'] = len(df)\n",
    "        Report.append(d)\n",
    "        \n",
    "    PhysicianReport = pd.DataFrame(Report)\n",
    "    return website2df, PhysicianReport\n",
    "\n",
    "website2validphy, PhysicianReport = get_website2validphyDF(website2path, website2ignorenpis)\n",
    "PhysicianReport.to_csv('Output/PhysicianReport.csv', index = False)\n",
    "PhysicianReport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198eb085",
   "metadata": {},
   "source": [
    "# Filter Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbd63e5",
   "metadata": {},
   "source": [
    "Three elements of Review\n",
    "\n",
    "1. `Tx`\n",
    "2. `Ts`\n",
    "3. `Sc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9ceb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:18:24.231500Z",
     "start_time": "2021-11-08T01:18:24.228744Z"
    }
   },
   "outputs": [],
   "source": [
    "CUTOFF_DATE = pd.to_datetime('2021-08-01', utc = 'UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc204a1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:18:24.237948Z",
     "start_time": "2021-11-08T01:18:24.232545Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_ValidTimeScore_Reviews(x):\n",
    "    new_x = []\n",
    "    bad_x = []\n",
    "    for i in x:\n",
    "        Flag = 'Bad'\n",
    "        try:\n",
    "            # datetime validation\n",
    "            date = pd.to_datetime(i['ReviewDate'], utc='UTC') # this step costs time.\n",
    "            i['ReviewDate'] = date\n",
    "            \n",
    "            # review score \n",
    "            i['ReviewScore'] = float(i['ReviewScore'])\n",
    "            if i['ReviewScore'] <=5 and i['ReviewScore'] >= 0:\n",
    "                Flag = 'Good'\n",
    "            else:\n",
    "                print(i)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if Flag == 'Bad':\n",
    "            bad_x.append(i)\n",
    "        else:\n",
    "            new_x.append(i)\n",
    "            \n",
    "    assert len(new_x) + len(bad_x) == len(x)\n",
    "    return new_x, bad_x\n",
    "\n",
    "\n",
    "def get_cutoff_reviews(x):\n",
    "    return [i for i in x if i['ReviewDate'] < CUTOFF_DATE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c54ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:18:24.247404Z",
     "start_time": "2021-11-08T01:18:24.238988Z"
    }
   },
   "outputs": [],
   "source": [
    "# good reviews: pass (1) Tx, (2) Ts, and (3) Sc\n",
    "# final reviews: before 2021.8.1\n",
    "\n",
    "\n",
    "def get_website2validreviewDF(website2validphy, MIN_TEXT_LENGTH, CUTOFF_DATE):\n",
    "    website2validrvw = {}\n",
    "    for website, df in website2validphy.items():\n",
    "        # Filter Review (1) Tx: Text Length\n",
    "        df['stdTx{}_reviews'.format(MIN_TEXT_LENGTH)] = df['stand_reviews'].apply(lambda x: [i for i in x if i['ReviewTextLen'] >= MIN_TEXT_LENGTH])\n",
    "        df['stdTx{}_reviews_num'.format(MIN_TEXT_LENGTH)] = df['stdTx{}_reviews'.format(MIN_TEXT_LENGTH)].apply(lambda x: len(x))\n",
    "\n",
    "        # Filter Review (2) Ts: Time and (3) Sc: Score\n",
    "        tmp = df['stdTx{}_reviews'.format(MIN_TEXT_LENGTH)].apply(filter_ValidTimeScore_Reviews)\n",
    "        df['good_review'] = [i[0] for i in tmp.values]\n",
    "        df['good_review_num'] = df['good_review'].apply(lambda x: len(x))\n",
    "        # df['bad_review']   = [i[1] for i in tmp.values]\n",
    "        # df['bad_review_num'] = df['bad_review' ].apply(lambda x: len(x))\n",
    "\n",
    "        # Filter Time: only here, as the timestamp is valid here.\n",
    "        df['final_review'] = df['good_review'].apply(get_cutoff_reviews)\n",
    "\n",
    "        # Final Info\n",
    "        df['final_review_num'] = df['final_review'].apply(lambda x:len(x))\n",
    "        df['final_review_date']  = df['final_review'].apply(lambda x: [i['ReviewDate'] for i in x])\n",
    "        df['final_review_score'] = df['final_review'].apply(lambda x: [i['ReviewScore'] for i in x])\n",
    "        df['final_review_length'] = df['final_review'].apply(lambda x:[i['ReviewTextLen'] for i in x])\n",
    "        website2validrvw[website] = df\n",
    "        \n",
    "    L = []\n",
    "    for name, df in website2validrvw.items():\n",
    "        \n",
    "        d = {}\n",
    "        d['name'] = name\n",
    "        d['rptratings'] = df['reported_ratings_num'].sum()\n",
    "        d['rptreviews'] = df['reported_reviews_num'].sum()\n",
    "        d['cltreviews'] = df['collected_reviews_num'].sum()\n",
    "        d['stdreviews'] = df['stand_reviews_num'].sum()\n",
    "        d['stdTx{}reviews'.format(MIN_TEXT_LENGTH)] = df['stdTx{}_reviews_num'.format(MIN_TEXT_LENGTH)].sum()\n",
    "        d['goodreviews'] = df['good_review_num'].sum()\n",
    "        d['finalreviews'] = df['final_review_num'].sum()\n",
    "        d['phynum'] = len(df)\n",
    "        d['phynumTxTsScAug'] = (df['final_review_num'] > 0).sum()\n",
    "        L.append(d)\n",
    "        \n",
    "        \n",
    "        cols = ['NPI', \n",
    "                'GraduationYear',\n",
    "                'reported_profile_score',\n",
    "                # 'reported_ratings_num', \n",
    "                # 'reported_reviews_num', \n",
    "                # 'collected_reviews_num',\n",
    "                # 'stand_reviews', \n",
    "                # 'stand_reviews_num', \n",
    "                # 'clct_time', \n",
    "                # 'stdTx0_reviews',\n",
    "                # 'stdTx0_reviews_num',\n",
    "                # 'good_review', \n",
    "                # 'good_review_num',\n",
    "                'final_review',\n",
    "                # 'final_review_num', \n",
    "                # 'final_review_date', \n",
    "                # 'final_review_score',\n",
    "                # 'final_review_length'\n",
    "               ]\n",
    "        df[cols].to_pickle('Output/MinText{}/{}.p'.format(MIN_TEXT_LENGTH, name))\n",
    "        \n",
    "    ReviewReport = pd.DataFrame(L)\n",
    "    return website2validrvw, ReviewReport\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f367b",
   "metadata": {},
   "source": [
    "## All Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8fc9cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:35:31.231077Z",
     "start_time": "2021-11-08T01:18:24.248295Z"
    }
   },
   "outputs": [],
   "source": [
    "MIN_TEXT_LENGTH = 0\n",
    "\n",
    "website2validphy, PhyReport = get_website2validphyDF(website2path, website2ignorenpis)\n",
    "website2validrvw, RvwReport = get_website2validreviewDF(website2validphy, MIN_TEXT_LENGTH, CUTOFF_DATE)\n",
    "\n",
    "RvwReport.to_csv('Output/MinText{}/ReviewReport.csv'.format(MIN_TEXT_LENGTH), index = False)\n",
    "RvwReport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c3d10",
   "metadata": {},
   "source": [
    "## Text Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6096cfd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:02.316392Z",
     "start_time": "2021-11-08T01:35:31.237432Z"
    }
   },
   "outputs": [],
   "source": [
    "MIN_TEXT_LENGTH = 1\n",
    "\n",
    "website2validphy, PhyReport = get_website2validphyDF(website2path, website2ignorenpis)\n",
    "website2validrvw, RvwReport = get_website2validreviewDF(website2validphy, MIN_TEXT_LENGTH, CUTOFF_DATE)\n",
    "\n",
    "RvwReport.to_csv('Output/MinText{}/ReviewReport.csv'.format(MIN_TEXT_LENGTH), index = False)\n",
    "RvwReport"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
